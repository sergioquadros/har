{
    "collab_server" : "",
    "contents" : "library(ggplot2);library(AppliedPredictiveModeling);library(caret)\nlibrary(ElemStatLearn);library(pgmm);library(rpart);library(gbm)\nlibrary(lubridate);library(forecast);library(e1071);library(corrplot)\nlibrary(magrittr);library(MASS);library(elasticnet)\n\n# test 1\n\nlibrary(ElemStatLearn)\n# data(vowel.data) # don't found\ndata(vowel.train)\n# 'data.frame':\t528 obs. of  11 variables\ndata(vowel.test)\n# 'data.frame':\t462 obs. of  11 variables\nset.seed(33833)\nsapply(vowel.train,class)\nsapply(vowel.train,class)\n#         y       x.1       x.2       x.3       x.4       x.5       x.6       x.7 \n# \"integer\" \"numeric\" \"numeric\" \"numeric\" \"numeric\" \"numeric\" \"numeric\" \"numeric\" \n#       x.8       x.9      x.10 \n# \"numeric\" \"numeric\" \"numeric\" \nunique(vowel.train$y)\n# [1]  1  2  3  4  5  6  7  8  9 10 11\n\nM <- cor(vowel.train)\nord <- corrMatOrder(M, order=\"AOE\")\nM2 <- M[ord,ord]\ncorrplot(M2)\ncorrplot.mixed(M2)\nhist(vowel.train$x.10)\nhistogram(vowel.train$y)\nvowel.train$y %<>% as.factor\n# Fit (1) a random forest predictor relating the factor variable y to the \n# remaining variables and (2) a boosted predictor using the \"gbm\" method. \n# Fit these both with the train() command in the caret package.\nset.seed(33833)\nfitControl <- trainControl(## 10-fold CV\n        method = \"repeatedcv\",\n        number = 10,\n        ## repeated ten times\n        repeats = 10)\nmod2 <- train(y ~.,method=\"gbm\",\n              trControl = fitControl,data=vowel.train)\ntrellis.par.set(caretTheme())\nplot(mod2)\nmod2\n# Stochastic Gradient Boosting \n# interaction.depth  n.trees  Accuracy   Kappa      Accuracy SD  Kappa SD  \n# 3                  150      0.8661483  0.8524165  0.02864928   0.03159912\n# second time\n# 3                  150      0.9272759  0.9199739  0.04159005   0.04574146\nset.seed(33833)\nmod1 <- train(y ~.,method=\"rf\",data=vowel.train, \n              trControl = fitControl,number=10)\ntrellis.par.set(caretTheme())\nplot(mod1)\nmod1\n# Random Forest \n# mtry  Accuracy   Kappa      Accuracy SD  Kappa SD  \n# 2    0.9715824  0.9687262  0.01829374   0.02013282\n# second time\n# 2    0.9714473  0.9685754  0.02728575   0.03002658\n\n# Predict on the testing set\npred1 <- predict(mod1,vowel.test); pred2 <- predict(mod2,vowel.test)\n# Extract accuracies for (1) random forests and (2) boosting\nconfusionMatrix(pred1, vowel.test$y)$overall[1]\n##  Accuracy  0.5952381 \nconfusionMatrix(pred2, vowel.test$y)$overall[1]\n##  Accuracy  0.508658 \n\npredDF <- data.frame(pred1=as.factor(pred1),\n                     pred2=as.factor(pred2),y=as.factor(vowel.test$y))\ntable(predDF)\n# out error\nsum(pred1[predDF$pred1 == predDF$pred2] == \n            predDF$y[predDF$pred1 == predDF$pred2]) / \n        sum(predDF$pred1 == predDF$pred2)\n# [1] 0.6440129\n# bizarre stacking\ncombModFit <- train(y ~.,method=\"gam\",data=predDF)\ncombPred <- predict(combModFit,predDF)\nggplot(predDF,aes(x=pred1,y=pred2))+geom_jitter(aes(colour=y))\n# What are the accuracies for the two approaches on the test data set?\n# What is the accuracy among the test set samples where the two methods agree?\n\n# in error\n# GBM 86,61% 92,73%\n# RF 97,16%  97,14%\n# concordance 72.29%\n\n\n\n# question 2\ndata(AlzheimerDisease)\nset.seed(3433)\nadData = data.frame(diagnosis,predictors)\ninTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]\ntraining = adData[ inTrain,]\ntesting = adData[-inTrain,]\n# Set the seed to 62433 and predict diagnosis with all the other variables \n# using a random forest (\"rf\"), boosted trees (\"gbm\") and linear discriminant \n# analysis (\"lda\") model. Stack the predictions together using random forests (\"rf\"). \n# What is the resulting accuracy on the test set? Is it better or worse than each \n# of the individual predictions?\nfitControl <- trainControl(## 10-fold CV\n        method = \"repeatedcv\",\n        number = 10,\n        ## repeated ten times\n        repeats = 10)\nset.seed(62433)\nm_rf <- train(diagnosis ~.,method=\"rf\",\n              trControl = fitControl,data=training)\ntrellis.par.set(caretTheme())\nplot(m_rf)\nm_rf\nset.seed(62433)\nm_gbm <- train(diagnosis ~.,method=\"gbm\",\n              trControl = fitControl,data=training)\ntrellis.par.set(caretTheme())\nplot(m_gbm)\nm_gbm\nset.seed(62433)\nm_lda <- train(diagnosis ~.,method=\"lda\",data=training)\n# trellis.par.set(caretTheme())\n# plot(m_lda)\n# Error in plot.train(m_lda) : \n#         There are no tuning parameters for this model.\nm_lda\n\np_rf <- predict(m_rf,testing)\np_gbm <- predict(m_gbm,testing)\np_lda <- predict(m_lda,testing)\nconfusionMatrix(p_rf, testing$diagnosis)$overall[1]\n# Accuracy 0.804878 \nconfusionMatrix(p_gbm, testing$diagnosis)$overall[1]\n# Accuracy 0.7926829 \nconfusionMatrix(p_lda, testing$diagnosis)$overall[1]\n# Accuracy  0.7682927 \npredDF <- data.frame(p_rf,p_gbm,p_lda,diagnosis=testing$diagnosis)\ncombo <- train(diagnosis ~.,method=\"rf\",\n               trControl = fitControl,data=predDF)\ntrellis.par.set(caretTheme())\nplot(combo)\ncombo\n# Random Forest\n# Resampling: Cross-Validated (10 fold, repeated 10 times) \n# mtry  Accuracy   Kappa      Accuracy SD  Kappa SD \n# 2     0.8001389  0.4313207  0.1265399    0.3572040\n# 3     0.8022222  0.4396670  0.1287718    0.3564317\n# The final value used for the model was mtry = 3. \np_combo <- predict(combo,testing)\nconfusionMatrix(p_combo, testing$diagnosis)$overall[1]\n# Accuracy 0.8292683 \n\n\n# question 3\nset.seed(3523)\ndata(concrete)\ninTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]\ntraining = concrete[ inTrain,]\ntesting = concrete[-inTrain,]\n# Set the seed to 233 and fit a lasso model to predict Compressive Strength. \n# Which variable is the last coefficient to be set to zero as the penalty \n# increases? (Hint: it may be useful to look up ?plot.enet).\nfitControl <- trainControl(## 10-fold CV\n        method = \"repeatedcv\",\n        number = 10,\n        ## repeated ten times\n        repeats = 10)\nset.seed(233)\nmlasso <- train(CompressiveStrength ~.,method=\"lasso\",\n              trControl = fitControl,data=training)\ntrellis.par.set(caretTheme())\nplot(mlasso)\nmlasso\n# The lasso \n# Resampling: Cross-Validated (10 fold, repeated 10 times) \n# fraction  RMSE      Rsquared   RMSE SD    Rsquared SD\n# 0.1       15.04079  0.3392044  0.9814284  0.07757215 \n# 0.5       11.38539  0.5746176  0.8176782  0.06460803 \n# 0.9       10.48855  0.6096160  0.7933223  0.06031299 \n# RMSE was used to select the optimal model using  the smallest value.\n# The final value used for the model was fraction = 0.9. \nmlasso$finalModel\n# Sequence of  moves:\n#      Cement Superplasticizer Age BlastFurnaceSlag Water FineAggregate FlyAsh\n# Var       1                5   8                2     4             7      3\n# Step      1                2   3                4     5             6      7\n#      FineAggregate FineAggregate CoarseAggregate <<<<<<< MY CHOICE  \n# Var             -7             7               6 11\n# Step             8             9              10 11\ntrellis.par.set(caretTheme())\nplot(mlasso)\np_la <- predict(mlasso,testing)\nsum(abs(testing$CompressiveStrength-p_la)>=1E-5)/length(p_la)\nqqplot(p_la,testing$CompressiveStrength)\nhistogram((testing$CompressiveStrength-p_la))\nplot.enet(mlasso$finalModel, xvar = \"penalty\", use.color = TRUE)\n# CoarseAggregate <<<<<<< MY CHOICE\n\n\n# question 4\n# Load the data on the number of visitors to the instructors blog from here:\n# https://d396qusza40orc.cloudfront.net/predmachlearn/gaData.csv\n# Using the commands:\nlibrary(lubridate) # For year() function below\ndat = read.csv(\"gaData.csv\")\ntraining = dat[year(dat$date) < 2012,]\ntesting = dat[(year(dat$date)) > 2011,]\ntstrain = ts(training$visitsTumblr)\n\n# Fit a model using the bats() function in the forecast package to the \n# training time series. Then forecast this model for the remaining time points. \n# For how many of the testing points is the true value within the 95% prediction \n# interval bounds?\nmod_ts <- bats(tstrain)\nfcast <- forecast(mod_ts, level = 95, h = dim(testing)[1])\nsum(fcast$lower < testing$visitsTumblr & testing$visitsTumblr < fcast$upper) / \n        dim(testing)[1]\n# [1] 0.9617021\n# plot(decompose(?????),xlab = \"Years+1\")\n\n#  question 5\nset.seed(3523)\nlibrary(AppliedPredictiveModeling)\ndata(concrete)\ninTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]\ntraining = concrete[ inTrain,]\ntesting = concrete[-inTrain,]\n# Set the seed to 325 and fit a support vector machine using the e1071 package \n# to predict Compressive Strength using the default settings. \n# Predict on the testing set. What is the RMSE?\n\nsapply(training, class)\nset.seed(325)\nmod_svm <- svm(CompressiveStrength~.,data=training)\n# trellis.par.set(caretTheme())\n# plot(mod_svm)\np_svm <- predict(mod_svm,testing)\naccuracy(p_svm,testing$CompressiveStrength)\n#                 ME     RMSE      MAE       MPE     MAPE\n# Test set 0.1682863 6.715009 5.120835 -7.102348 19.27739\n\n# accuracy(f, x, test=NULL, d=NULL, D=NULL)     {forecast}\n# f An object of class \"forecast\", or a numerical vector containing forecasts. \n# x An optional numerical vector containing actual values\n# \n# ME: Mean Error\n# RMSE: Root Mean Squared Error\n# MAE: Mean Absolute Error\n# MPE: Mean Percentage Error\n# MAPE: Mean Absolute Percentage Error\n# MASE: Mean Absolute Scaled Error\n# ACF1: Autocorrelation of errors at lag 1.\n\n# EXAMPLE OF FORECAST'S USING\nfit1 <- rwf(EuStockMarkets[1:200,1],h=100)\nfit2 <- meanf(EuStockMarkets[1:200,1],h=100)\naccuracy(fit1)\naccuracy(fit2)\naccuracy(fit1,EuStockMarkets[201:300,1])\naccuracy(fit2,EuStockMarkets[201:300,1])\nplot(fit1)\nlines(EuStockMarkets[1:300,1])\n",
    "created" : 1459047690897.000,
    "dirty" : true,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2338452457",
    "id" : "73813BC9",
    "lastKnownWriteTime" : 1458954993,
    "last_content_update" : 1459047775390,
    "path" : "~/Documentos/dataScience/datascienceJH/ml_JH032016/week4/test4.R",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 3,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}