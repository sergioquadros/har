install.packages("doParallel")
source('~/.active-rstudio-document', echo=TRUE)
install.packages("pROC")
source('~/.active-rstudio-document', echo=TRUE)
pdf('plots.pdf')
for(stat in c('Accuracy', 'Kappa', 'AccuracyLower', 'AccuracyUpper', 'AccuracyPValue',
'Sensitivity', 'Specificity', 'Pos_Pred_Value',
'Neg_Pred_Value', 'Detection_Rate', 'ROC', 'logLoss')) {
print(plot(model, metric=stat))
}
dev.off()
pdf('plots.pdf')
for(stat in c('Accuracy', 'Kappa', 'AccuracyLower', 'AccuracyUpper', 'AccuracyPValue',
'Sensitivity', 'Specificity', 'Pos_Pred_Value',
'Neg_Pred_Value', 'Detection_Rate', 'ROC', 'logLoss')) {
print(plot(model, metric=stat))
}
dev.off()
dev.off()
pdf('plots.pdf')
for(stat in c('Accuracy', 'Kappa', 'AccuracyLower', 'AccuracyUpper', 'AccuracyPValue',
'Sensitivity', 'Specificity', 'Pos_Pred_Value',
'Neg_Pred_Value', 'Detection_Rate', 'ROC', 'logLoss')) {
print(plot(model, metric=stat))
}
dev.off()
install.packages("glm2")
library(knitr);library(rmarkdown);library(ggplot2);library(magrittr);library(dplyr);library(caret);library(gridExtra); library(RCurl); library(corrplot);library(e1071); library(rattle); library(glm2);library(doParallel)
# knitr::opts_chunk$set(echo = FALSE)
#CLEAR WORKSPACE
rm(list = ls(all = TRUE))
gc(reset=TRUE)
#Setup parallel cluster
#If running on the command line of linux, use method='fork'
cl <- makeCluster(detectCores(), type='PSOCK')
registerDoParallel(cl)
# file names and url
URLtrain <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
URLtest <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
NAMEtrain <- "pml_training.csv"
NAMEtest <- "pml_testing.csv"
# Create directory
if (!file.exists("./figures")) {
dir.create("./figures")
}
# Download
if (!file.exists(NAMEtrain)) {
download.file(URLtrain, destfile=NAMEtrain)
}
if (!file.exists(NAMEtest)) {
download.file(URLtest, destfile=NAMEtest)
}
# load data and clean 'NA' & meaningless features
training <- read.csv(NAMEtrain, na.strings = c("NA", ""))
testing <- read.csv(NAMEtest, na.strings = c("NA", ""))
training1 <- training[, colSums(is.na(training)) == 0]
testing1 <- testing[, colSums(is.na(testing)) == 0]
training0 <- training1[, -c(1:7)]
testing0 <- testing1[, -c(1:7)]
# # There were some clumps with high covariances between features
# M <- cor(training0[, c(1:52)])
# ord <- corrMatOrder(M, order="AOE")
# M2 <- M[ord,ord]
# corrplot(M2)
# # Skeewness
# sapply(training0[, c(1:52)],skeewness)
# # The classe outcome has this distribution:
# histogram(training$classe)
fitControl <- trainControl(method = "repeatedcv", number = 6, repeats = 6)
set.seed(141593)
inTrain <- createDataPartition(training0$classe, p = 0.65)[[1]]
trainSub <- training0[ inTrain,]
testSub <- training0[-inTrain,]
set.seed(141593)
mod_glm <- train(classe ~.,method="glm", trControl=fitControl,data=trainSub)
trellis.par.set(caretTheme())
plot(mod_glm)
pred_glm <- predict(mod_glm,testSub)
confusionMatrix(pred_glm, testSub$classe)
set.seed(141593)
mod_rp <- train(classe ~.,method="rp", trControl=fitControl,data=trainSub)
trellis.par.set(caretTheme())
plot(mod_rp)
pred_rp <- predict(mod_rp,testSub)
confusionMatrix(pred_rp, testSub$classe)
set.seed(141593)
mod_rp <- train(classe ~.,method="rpar", trControl=fitControl,data=trainSub)
trellis.par.set(caretTheme())
plot(mod_rp)
pred_rp <- predict(mod_rp,testSub)
confusionMatrix(pred_rp, testSub$classe)
set.seed(141593)
mod_rp <- train(classe ~.,method="rpart", trControl=fitControl,data=trainSub)
trellis.par.set(caretTheme())
plot(mod_rp)
pred_rp <- predict(mod_rp,testSub)
confusionMatrix(pred_rp, testSub$classe)
install.packages("rpart")
install.packages("randomForest")
library(knitr);library(rmarkdown);library(ggplot2);library(magrittr);library(dplyr);library(caret);library(gridExtra); library(RCurl); library(corrplot);library(e1071); library(rattle); library(glm2);library(doParallel);library(rpart);library(randomForest)
# knitr::opts_chunk$set(echo = FALSE)
#CLEAR WORKSPACE
rm(list = ls(all = TRUE))
gc(reset=TRUE)
#Setup parallel cluster
#If running on the command line of linux, use method='fork'
cl <- makeCluster(detectCores(), type='PSOCK')
registerDoParallel(cl)
# file names and url
URLtrain <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
URLtest <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
NAMEtrain <- "pml_training.csv"
NAMEtest <- "pml_testing.csv"
# Create directory
if (!file.exists("./figures")) {
dir.create("./figures")
}
# Download
if (!file.exists(NAMEtrain)) {
download.file(URLtrain, destfile=NAMEtrain)
}
if (!file.exists(NAMEtest)) {
download.file(URLtest, destfile=NAMEtest)
}
# load data and clean 'NA' & meaningless features
training <- read.csv(NAMEtrain, na.strings = c("NA", ""))
testing <- read.csv(NAMEtest, na.strings = c("NA", ""))
training1 <- training[, colSums(is.na(training)) == 0]
testing1 <- testing[, colSums(is.na(testing)) == 0]
training0 <- training1[, -c(1:7)]
testing0 <- testing1[, -c(1:7)]
# # There were some clumps with high covariances between features
# M <- cor(training0[, c(1:52)])
# ord <- corrMatOrder(M, order="AOE")
# M2 <- M[ord,ord]
# corrplot(M2)
# # Skeewness
# sapply(training0[, c(1:52)],skeewness)
# # The classe outcome has this distribution:
# histogram(training$classe)
fitControl <- trainControl(method = "repeatedcv", number = 6, repeats = 6)
set.seed(141593)
inTrain <- createDataPartition(training0$classe, p = 0.65)[[1]]
trainSub <- training0[ inTrain,]
testSub <- training0[-inTrain,]
set.seed(141593)
mod_glm <- train(classe ~.,method="glm", trControl=fitControl,data=trainSub)
trellis.par.set(caretTheme())
plot(mod_glm)
pred_glm <- predict(mod_glm,testSub)
confusionMatrix(pred_glm, testSub$classe)
install.packages("arm")
```{r setup, message=FALSE, echo=TRUE}
library(knitr);library(rmarkdown);library(ggplot2);library(magrittr);library(dplyr);library(caret);library(gridExtra); library(RCurl); library(corrplot);library(e1071); library(rattle); library(glm2);library(doParallel);library(rpart);library(randomForest);library(arm)
# knitr::opts_chunk$set(echo = FALSE)
#CLEAR WORKSPACE
rm(list = ls(all = TRUE))
gc(reset=TRUE)
#Setup parallel cluster
#If running on the command line of linux, use method='fork'
cl <- makeCluster(detectCores(), type='PSOCK')
registerDoParallel(cl)
# file names and url
URLtrain <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
URLtest <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
NAMEtrain <- "pml_training.csv"
NAMEtest <- "pml_testing.csv"
# Create directory
if (!file.exists("./figures")) {
dir.create("./figures")
}
# Download
if (!file.exists(NAMEtrain)) {
download.file(URLtrain, destfile=NAMEtrain)
}
if (!file.exists(NAMEtest)) {
download.file(URLtest, destfile=NAMEtest)
}
# load data and clean 'NA' & meaningless features
training <- read.csv(NAMEtrain, na.strings = c("NA", ""))
testing <- read.csv(NAMEtest, na.strings = c("NA", ""))
training1 <- training[, colSums(is.na(training)) == 0]
testing1 <- testing[, colSums(is.na(testing)) == 0]
training0 <- training1[, -c(1:7)]
testing0 <- testing1[, -c(1:7)]
# # There were some clumps with high covariances between features
# M <- cor(training0[, c(1:52)])
# ord <- corrMatOrder(M, order="AOE")
# M2 <- M[ord,ord]
# corrplot(M2)
# # Skeewness
# sapply(training0[, c(1:52)],skeewness)
# # The classe outcome has this distribution:
# histogram(training$classe)
fitControl <- trainControl(method = "repeatedcv", number = 6, repeats = 6)
set.seed(141593)
inTrain <- createDataPartition(training0$classe, p = 0.65)[[1]]
trainSub <- training0[ inTrain,]
testSub <- training0[-inTrain,]
set.seed(141593)
mod_glm <- train(classe ~.,method="bayesglm", trControl=fitControl,data=trainSub)
trellis.par.set(caretTheme())
plot(mod_glm)
pred_glm <- predict(mod_glm,testSub)
confusionMatrix(pred_glm, testSub$classe)
set.seed(141593)
mod_rp <- train(classe ~.,method="rpart", trControl=fitControl,data=trainSub)
trellis.par.set(caretTheme())
plot(mod_rp)
pred_rp <- predict(mod_rp,testSub)
confusionMatrix(pred_rp, testSub$classe)
set.seed(141593)
mod_rforest <- train(classe ~.,method="rf", trControl=fitControl,data=trainSub)
packrat::snapshot(prompt = FALSE)
stopCluster(cl)
rm(list = ls(all = TRUE))
gc(reset=TRUE)
cl <- makeCluster(detectCores(), type='PSOCK')
# Chunk 1: setup
library(knitr);library(rmarkdown);library(ggplot2);library(magrittr);library(dplyr);library(caret);library(gridExtra); library(RCurl); library(corrplot);library(e1071); library(rattle); library(glm2);library(doParallel);library(rpart);library(randomForest);library(arm)
#CLEAR WORKSPACE
rm(list = ls(all = TRUE))
# Chunk 2: original_data
# file names and url
URLtrain <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
URLtest <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
NAMEtrain <- "pml_training.csv"
NAMEtest <- "pml_testing.csv"
# Create directory
if (!file.exists("./figures")) {
dir.create("./figures")
}
# Download
if (!file.exists(NAMEtrain)) {
download.file(URLtrain, destfile=NAMEtrain)
}
if (!file.exists(NAMEtest)) {
download.file(URLtest, destfile=NAMEtest)
}
# load data and clean 'NA' & meaningless features
training <- read.csv(NAMEtrain, na.strings = c("NA", ""))
testing <- read.csv(NAMEtest, na.strings = c("NA", ""))
training1 <- training[, colSums(is.na(training)) == 0]
testing1 <- testing[, colSums(is.na(testing)) == 0]
training0 <- training1[, -c(1:7)]
testing0 <- testing1[, -c(1:7)]
# Chunk 3: exloratory
# # There were some clumps with high covariances between features
# M <- cor(training0[, c(1:52)])
# ord <- corrMatOrder(M, order="AOE")
# M2 <- M[ord,ord]
# corrplot(M2)
# # Skeewness
# sapply(training0[, c(1:52)],skeewness)
# # The classe outcome has this distribution:
# histogram(training$classe)
# Chunk 4: split_control
fitControl <- trainControl(method = "cv", number=7)#repeatedcv", number = 6, repeats = 3)
set.seed(141593)
inTrain <- createDataPartition(training0$classe, p = 0.65)[[1]]
trainSub <- training0[ inTrain,]
testSub <- training0[-inTrain,]
# Chunk 5: knn_model
set.seed(141593)
mod_knn <- train(classe ~.,method="knn",trControl=fitControl,data=trainSub)
print(mod_knn, digits = 3)
trellis.par.set(caretTheme())
plot(mod_knn)
pred_knn <- predict(mod_knn,testSub)
confusionMatrix(pred_knn, testSub$classe)
# Chunk 6: rparty_model
set.seed(141593)
mod_rp <- train(classe ~.,method="rpart", trControl=fitControl,data=trainSub)
print(mod_rp, digits = 3)
trellis.par.set(caretTheme())
plot(mod_rp)
pred_rp <- predict(mod_rp,testSub)
confusionMatrix(pred_rp, testSub$classe)
# Chunk 7: randomForest_model
set.seed(141593)
mod_rforest <- train(classe ~.,method="rf", trControl=fitControl,data=trainSub)
print(mod_rforest, digits = 3)
trellis.par.set(caretTheme())
plot(mod_rforest)
pred_rforest <- predict(mod_rforest,testSub)
confusionMatrix(pred_rforest, testSub$classe)
# Chunk 8: stop_cluster
stopCluster(cl)
ggplot(predDF,aes(x=pred_knn,y=testSub$classe))+geom_jitter(aes(colour=testSub$classe))
predDF <- data.frame(pred_knn,testSub$classe)
ggplot(predDF,aes(x=pred_knn,y=testSub$classe))+geom_jitter(aes(colour=testSub$classe))
predDF <- data.frame(pred_rforest,testSub$classe)
ggplot(predDF,aes(x=pred_rforest,y=testSub$classe))+
geom_jitter(aes(colour=testSub$classe))
plot(mod_rforest)
trellis.par.set(caretTheme())
plot(mod_knn)
predDF2 <- data.frame(pred_rforest,testSub$classe)
ggplot(predDF2,aes(x=pred_rforest,y=testSub$classe))+
geom_jitter(aes(colour=testSub$classe))
ggplot(predDF,aes(x=pred_knn,y=testSub$classe))+
geom_jitter(aes(colour=testSub$classe))+xlab("Class Predict")+
ylab("Actual")+ggtitle(k-Nearest Neighbors)
ggplot(predDF,aes(x=pred_knn,y=testSub$classe))+
geom_jitter(aes(colour=testSub$classe))+xlab("Class Predict")+
ylab("Actual")+ggtitle(k-Nearest Neighbors)
ggplot(predDF,aes(x=pred_knn,y=testSub$classe))+geom_jitter(aes(colour=testSub$classe))+xlab("Class Predict")+ylab("Actual")+ggtitle(k-Nearest Neighbors)
ggplot(predDF,aes(x=pred_knn,y=testSub$classe))+geom_jitter(aes(colour=testSub$classe))
ggplot(predDF,aes(x=pred_knn,y=testSub$classe))+geom_jitter(aes(colour=testSub$classe))+xlab("Class Predict")+ylab("Actual")+ggtitle("k-Nearest Neighbors")
ggplot(predDF,aes(x=pred_knn,y=testSub$classe))+geom_jitter(aes(colour=testSub$classe))+xlab("Class Predict")+ylab("Actual")+ggtitle("k-Nearest Neighbors")+ theme(legend.title=element_blank())
?grid.arrange
p3 <- ggplot(predDF,aes(x=pred_knn,y=testSub$classe))+geom_jitter(aes(colour=testSub$classe))+xlab("Class Predict")+ylab("Actual")+ggtitle("k-Nearest Neighbors")+ theme(legend.title=element_blank())
p4 <- ggplot(predDF2,aes(x=pred_rforest,y=testSub$classe))+
geom_jitter(aes(colour=testSub$classe))+xlab("Class Predict")+ylab("Actual")+ggtitle("Random Forest")+theme(legend.title=element_blank())
grid.arrange(p3,p4, ncol=2, nrow =1, title("Cross-validation Accuracy"))
p3 <- ggplot(predDF,aes(x=pred_knn,y=testSub$classe))+geom_jitter(aes(colour=testSub$classe))+xlab("Class Predict")+ylab("Actual")+ggtitle("k-Nearest Neighbors")+ theme(legend.title=element_blank())
p4 <- ggplot(predDF2,aes(x=pred_rforest,y=testSub$classe))+
geom_jitter(aes(colour=testSub$classe))+xlab("Class Predict")+ylab("Actual")+ggtitle("Random Forest")+theme(legend.title=element_blank())
grid.arrange(p3,p4, ncol=2, nrow =1, title="Cross-validation Accuracy")
p3 <- ggplot(predDF,aes(x=pred_knn,y=testSub$classe))+geom_jitter(aes(colour=testSub$classe))+xlab("Class Predict")+ylab("Actual")+ggtitle("k-Nearest Neighbors")+ theme(legend.title=element_blank())
p4 <- ggplot(predDF2,aes(x=pred_rforest,y=testSub$classe))+
geom_jitter(aes(colour=testSub$classe))+xlab("Class Predict")+ylab("Actual")+ggtitle("Random Forest")+theme(legend.title=element_blank())
grid.arrange(p3,p4, ncol=2, nrow =1, title="Cross-validation Accuracy")
grid.arrange(p3,p4, ncol=2, title="Cross-validation Accuracy")
p1 <- corrplot(M2)
# Skeewness
# sapply(training0[, c(1:52)],skeewness)
# The classe outcome has this distribution:
p2 <- histogram(training$classe)
grid.arrange(p1,p2, title="Covariance & Class Distribution")
p1 <- corrplot(M2)
M <- cor(training0[, c(1:52)])
ord <- corrMatOrder(M, order="AOE")
M2 <- M[ord,ord]
p1 <- corrplot(M2)
p2 <- histogram(training$classe)
histogram(training$classe)
grid.arrange(p1,p2, title="Covariance & Class Distribution")
library(knitr);library(rmarkdown);library(ggplot2);library(magrittr);library(caret);library(gridExtra); library(RCurl); library(corrplot);library(e1071);library(rpart);library(randomForest)
#CLEAR WORKSPACE
rm(list = ls(all = TRUE))
grid.arrange(p1, p2, ncol=2, main="Covariance & Class Distribution")
M <- cor(training0[, c(1:52)])
ord <- corrMatOrder(M, order="AOE")
M2 <- M[ord,ord]
p1 <- corrplot(M2)
library(knitr);library(rmarkdown);library(ggplot2);library(magrittr);library(caret);library(gridExtra); library(RCurl); library(corrplot);library(e1071);library(rpart);library(randomForest)
#CLEAR WORKSPACE
rm(list = ls(all = TRUE))
# file names and url
URLtrain <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
URLtest <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
NAMEtrain <- "pml_training.csv"
NAMEtest <- "pml_testing.csv"
# Create directory
if (!file.exists("./figures")) {
dir.create("./figures")
}
# Download
if (!file.exists(NAMEtrain)) {
download.file(URLtrain, destfile=NAMEtrain)
}
if (!file.exists(NAMEtest)) {
download.file(URLtest, destfile=NAMEtest)
}
# Load data and clean 'NA' & meaningless features
training <- read.csv(NAMEtrain, na.strings = c("NA", ""))
testing <- read.csv(NAMEtest, na.strings = c("NA", ""))
training1 <- training[, colSums(is.na(training)) == 0]
testing1 <- testing[, colSums(is.na(testing)) == 0]
training0 <- training1[, -c(1:7)]
testing0 <- testing1[, -c(1:7)]
# There were some clumps with high covariances between features
M <- cor(training0[, c(1:52)])
ord <- corrMatOrder(M, order="AOE")
M2 <- M[ord,ord]
p1 <- corrplot(M2)
# Skeewness
# sapply(training0[, c(1:52)],skeewness)
# The classe outcome has this distribution:
p2 <- histogram(training$classe)
grid.arrange(p1, p2, ncol=2, main="Covariance & Class Distribution")
# There were some clumps with high covariances between features
M <- cor(training0[, c(1:52)])
ord <- corrMatOrder(M, order="AOE")
M2 <- M[ord,ord]
p1 <- corrplot(M2)
p1
# Skeewness
# sapply(training0[, c(1:52)],skeewness)
# The classe outcome has this distribution:
p2 <- histogram(training$classe)
p2
# Chunk 1: setup
library(knitr);library(rmarkdown);library(ggplot2);library(magrittr);library(caret);library(gridExtra); library(RCurl); library(corrplot);library(e1071);library(rpart);library(randomForest)
#CLEAR WORKSPACE
rm(list = ls(all = TRUE))
# Chunk 2: original_data
# file names and url
URLtrain <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
URLtest <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
NAMEtrain <- "pml_training.csv"
NAMEtest <- "pml_testing.csv"
# Create directory
if (!file.exists("./figures")) {
dir.create("./figures")
}
# Download
if (!file.exists(NAMEtrain)) {
download.file(URLtrain, destfile=NAMEtrain)
}
if (!file.exists(NAMEtest)) {
download.file(URLtest, destfile=NAMEtest)
}
# Load data and clean 'NA' & meaningless features
training <- read.csv(NAMEtrain, na.strings = c("NA", ""))
testing <- read.csv(NAMEtest, na.strings = c("NA", ""))
training1 <- training[, colSums(is.na(training)) == 0]
testing1 <- testing[, colSums(is.na(testing)) == 0]
training0 <- training1[, -c(1:7)]
testing0 <- testing1[, -c(1:7)]
# Chunk 3: exloratory
# There were some clumps with high covariances between features
M <- cor(training0[, c(1:52)])
ord <- corrMatOrder(M, order="AOE")
M2 <- M[ord,ord]
p1 <- corrplot(M2)
p1
# Skeewness
# sapply(training0[, c(1:52)],skeewness)
# The classe outcome has this distribution:
p2 <- histogram(training$classe)
p2
# Chunk 4: split_control
fitControl <- trainControl(method = "cv", number=7)#repeatedcv", number = 6, repeats = 3)
set.seed(141593)
inTrain <- createDataPartition(training0$classe, p = 0.65)[[1]]
trainSub <- training0[ inTrain,]
testSub <- training0[-inTrain,]
# Chunk 5: knn_model
set.seed(141593)
mod_knn <- train(classe ~.,method="knn",trControl=fitControl,data=trainSub)
print(mod_knn, digits = 3)
pred_knn <- predict(mod_knn,testSub)
confusionMatrix(pred_knn, testSub$classe)
predDF <- data.frame(pred_knn,testSub$classe)
# Chunk 6: randomForest_model
set.seed(141593)
mod_rforest <- train(classe ~.,method="rf", trControl=fitControl,data=trainSub)
print(mod_rforest, digits = 3)
pred_rforest <- predict(mod_rforest,testSub)
confusionMatrix(pred_rforest, testSub$classe)
predDF2 <- data.frame(pred_rforest,testSub$classe)
# Chunk 7: results_crossvalidation
trellis.par.set(caretTheme())
p3 <- plot(mod_knn)
trellis.par.set(caretTheme())
p4 <- plot(mod_rforest)
p5 <- ggplot(predDF,aes(x=pred_knn,y=testSub$classe))+geom_jitter(aes(colour=testSub$classe))+xlab("Class Predict")+ylab("Actual")+ggtitle("k-Nearest Neighbors")+ theme(legend.title=element_blank())
p6 <- ggplot(predDF2,aes(x=pred_rforest,y=testSub$classe))+
geom_jitter(aes(colour=testSub$classe))+xlab("Class Predict")+ylab("Actual")+ggtitle("Random Forest")+theme(legend.title=element_blank())
grid.arrange(p3,p4,p5,p6, ncol=2, nrow=2, main="Cross-validation Accuracy")
p3
p4
p5
p6
grid.arrange(p3,p4,p5,p6, ncol = 2, nrow = 2, main = "Cross-validation Accuracy")
grid.arrange(p3,p4,p5,p6, ncol = 2, nrow = 2)
titulo <- "Cross-validation Accuracy"
grid.arrange(p3,p4,p5,p6, ncol = 2, nrow = 2, main = titulo)
grid.arrange(p3,p4,p5,p6, ncol = 2, nrow = 3, main = titulo)
grid.arrange(p3,p4,p5,p6, ncol = 2, main = titulo)
grid.arrange(p3,p4,p5,p6, ncol = 2, nrow = 3, main = titulo)
grid.arrange(p3,p4,p5,p6, ncol = 2, nrow = 2)#, main = titulo)
?corrplot
corrplot(M2)
corrplot.mixed(M2)
corrplot.mixed(M2)
mod_rforest
mod_knn
mod_rforest
confusionMatrix
confusionMatrix(pred_rforest, testSub$classe)
vv <- confusionMatrix(pred_rforest, testSub$classe)
str(vv)
vv$overall[1]
str(mod_rforest)
mod_rforest$resample$Accuracy[1]
sum(predict(mod_rforest, testing0)==testing0$classe)/20
predict(mod_rforest, testing0)
testing0$classe
View(testing0)
